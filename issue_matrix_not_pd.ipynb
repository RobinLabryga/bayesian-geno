{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linalg error because of cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical issues can cause the K_known_known to not be positive definite despite the kernel being a covariance function.\n",
    "Adding noise to the GP can solve this issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gaussian_process.GPfunctions as gp\n",
    "from gaussian_process import GaussianProcess\n",
    "from gaussian_process.kernels import SquaredExponentialKernel, CubicKernel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(start=0.0, stop=1.0, num=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(\n",
    "    [\n",
    "        0.00000000e00,\n",
    "        1.00000000e00,\n",
    "        1.69918210e-01,\n",
    "        2.41870758e-05,\n",
    "        2.07987347e-05,\n",
    "        2.07963787e-05,\n",
    "        2.08048677e-05,\n",
    "    ]\n",
    ")\n",
    "f_train = np.array(\n",
    "    [\n",
    "        1.19884924e02,\n",
    "        1.59770254e10,\n",
    "        4.61198173e08,\n",
    "        1.13152862e02,\n",
    "        1.12969950e02,\n",
    "        1.12969951e02,\n",
    "        1.12969950e02,\n",
    "    ]\n",
    ")\n",
    "g_train = np.array(\n",
    "    [\n",
    "        -664786.5771969751,\n",
    "        31954716085.865658,\n",
    "        5429136006.379254,\n",
    "        108120.58844165073,\n",
    "        -155.13284739461844,\n",
    "        -230.42261970330514,\n",
    "        40.849419301530375,\n",
    "    ]\n",
    ")\n",
    "f_noise = 1e-14\n",
    "g_noise = 1e-14\n",
    "\n",
    "kernel = SquaredExponentialKernel(l=1.0 / (2 * len(X_train)))\n",
    "\n",
    "GP_posterior = GaussianProcess(\n",
    "    kernel,\n",
    "    x_known=X_train,\n",
    "    f_known=f_train,\n",
    "    g_known=g_train,\n",
    "    f_noise=f_noise,\n",
    "    g_noise=g_noise,\n",
    ")\n",
    "\n",
    "posterior_mean, posterior_variance = GP_posterior(X)\n",
    "posterior_std = GP_posterior.std_deviation(X, variance=posterior_variance)\n",
    "posterior_mean_derivative, posterior_mean_derivative_variance = GP_posterior.derivative(\n",
    "    X\n",
    ")\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1, sharey=True)\n",
    "\n",
    "ax1.scatter(X_train, f_train, label=\"Observations\")\n",
    "gp.plot_gp(ax1, X, posterior_mean, posterior_std)\n",
    "gp.plot_label(ax1, \"Gaussian Process\")\n",
    "\n",
    "fig.suptitle(\"Squared exponential kernel sampled\")\n",
    "fig.set_figwidth(15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
