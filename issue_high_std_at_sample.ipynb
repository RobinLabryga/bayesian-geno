{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Std at training points is high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The std-deviation at the points we have used to condition the GP is very high. This is because of a bad choice of hyperparameters for the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gaussian_process.GPfunctions as gp\n",
    "from gaussian_process import GaussianProcess\n",
    "from gaussian_process.kernels import SquaredExponentialKernel, CubicKernel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(start=0.0, stop=1.0, num=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve by varying hyperparameters\n",
    "kernel = SquaredExponentialKernel(l=1)\n",
    "\n",
    "X_train = np.array([0.0, 1.0, 0.5, 0.21797318, 0.83333875])\n",
    "f_train = np.array(\n",
    "    [4.54568576e-07, 1.45570662e-07, 2.47127271e-07, 3.51116916e-07, 1.67656995e-07]\n",
    ")\n",
    "g_train = np.array(\n",
    "    [\n",
    "        -5.207673619287845e-07,\n",
    "        -9.722857176215605e-08,\n",
    "        -3.08997887937976e-07,\n",
    "        -4.2844720967864284e-07,\n",
    "        -1.678160337877302e-07,\n",
    "    ]\n",
    ")\n",
    "f_noise = 1e-14\n",
    "g_noise = 1e-14\n",
    "\n",
    "GP_posterior = GaussianProcess(\n",
    "    kernel,\n",
    "    x_known=X_train,\n",
    "    f_known=f_train,\n",
    "    g_known=g_train,\n",
    "    f_noise=f_noise,\n",
    "    g_noise=g_noise,\n",
    ")\n",
    "\n",
    "posterior_mean, posterior_variance = GP_posterior(X)\n",
    "posterior_std = GP_posterior.std_deviation(X, variance=posterior_variance)\n",
    "posterior_mean_derivative, posterior_mean_derivative_variance = GP_posterior.derivative(\n",
    "    X\n",
    ")\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1, sharey=True)\n",
    "\n",
    "ax1.scatter(X_train, f_train, label=\"Observations\")\n",
    "gp.plot_gp(ax1, X, posterior_mean, posterior_std)\n",
    "gp.plot_label(ax1, \"Gaussian Process\")\n",
    "\n",
    "fig.suptitle(\"Squared exponential kernel\")\n",
    "fig.set_figwidth(15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
